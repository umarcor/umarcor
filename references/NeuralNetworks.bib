@inproceedings{wu18,
  author = {Wu, Bichen and Wan, Alvin and Yue, Xiangyu and Jin, Peter and Zhao, Sicheng and Golmant, Noah and Gholaminejad, Amir and Gonzalez, Joseph and Keutzer, Kurt},
  booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title = {Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions},
  year = {2018},
  volume = {},
  number = {},
  pages = {9127-9135},
  doi={10.1109/CVPR.2018.00951}
}

@article{parhi20,
  author = {Parhi, Keshab K. and Unnikrishnan, Nanda K.},
  journal = {IEEE Open Journal of Circuits and Systems},
  title = {Brain-Inspired Computing: Models and Architectures},
  year = {2020},
  volume = {1},
  number = {},
  pages = {185-204},
  doi = {10.1109/OJCAS.2020.3032092}
}

@inproceedings{aghapour22,
  author = {Aghapour, Ehsan and Sapra, Dolly and Pimentel, Andy and Pathania, Anuj},
  title = {CPU-GPU Layer-Switched Low Latency CNN Inference},
  booktitle = {25th Euromicro Conference on Digital System Design (DSD)},
  year = {2022}
}

@online{gh:ARMComputeLibrary,
  author = {Barbier, Anthony and {contributors}},
  title = {{Computer vision and machine learning functions optimised for both Arm CPUs and GPUs using SIMD technologies}},
  url = {https://github.com/ARM-software/ComputeLibrary},
}

@article{cantero22,
  author = {Cantero, David and Esnaola-Gonzalez, Iker and Miguel-Alonso, Jose and Jauregi, Ekaitz},
  title = {Benchmarking Object Detection Deep Learning Models in Embedded Devices},
  journal = {Sensors},
  volume = {22},
  year = {2022},
  number = {11},
  article-number = {4205},
  url = {https://www.mdpi.com/1424-8220/22/11/4205},
  pubmedid = {35684827},
  issn = {1424-8220},
  abstract = {Object detection is an essential capability for performing complex tasks in robotic applications. Today, deep learning (DL) approaches are the basis of state-of-the-art solutions in computer vision, where they provide very high accuracy albeit with high computational costs. Due to the physical limitations of robotic platforms, embedded devices are not as powerful as desktop computers, and adjustments have to be made to deep learning models before transferring them to robotic applications. This work benchmarks deep learning object detection models in embedded devices. Furthermore, some hardware selection guidelines are included, together with a description of the most relevant features of the two boards selected for this benchmark. Embedded electronic devices integrate a powerful AI co-processor to accelerate DL applications. To take advantage of these co-processors, models must be converted to a specific embedded runtime format. Five quantization levels applied to a collection of DL models are considered; two of them allow the execution of models in the embedded general-purpose CPU and are used as the baseline to assess the improvements obtained when running the same models with the three remaining quantization levels in the AI co-processors. The benchmark procedure is explained in detail, and a comprehensive analysis of the collected data is presented. Finally, the feasibility and challenges of the implementation of embedded object detection applications are discussed.},
  doi = {10.3390/s22114205}
}
